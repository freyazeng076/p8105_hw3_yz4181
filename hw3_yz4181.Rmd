---
title: "hw3_yz4181"
author: "Yuanyuan Zeng(yz4181)"
date: "10/12/2021"
output: github_document
---

```{r, echo=FALSE}
library(tidyverse)
library(p8105.datasets)
library(lubridate)
```

## Problem 1

```{r, message = FALSE}
data("instacart")

# find the number of aisle and aisle that the most items ordered from
aisles_df =
  instacart %>% 
  group_by(aisle) %>% 
  summarize(order_times = n()) %>% 
  arrange(desc(order_times))

nrow(aisles_df)
head(aisles_df, 1)

# making plot showing number of items order in each aisle
aisles_df %>% 
  filter(
    order_times > 10000) %>% 
  mutate(
    aisle = factor(aisle), 
    aisle = fct_reorder(aisle, order_times)
  ) %>% 
  ggplot(aes(x = aisle, y = order_times)) +
  geom_point(alpha = .5) +
  labs(
    title = "Figure1. Number of items ordered from each aisle",
    x = "Aisle",
    y = "Number of items ordered") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

# Table showing most popular items in three aisles
most_popular_item = 
  instacart %>% 
  filter(
    aisle %in% c("baking ingredients", 
                 "dog food care", 
                 "packaged vegetables fruits")) %>% 
  group_by(aisle,product_name) %>% 
  summarize(number_of_order_times = n()) %>% 
  mutate(
    order_ranking = min_rank(desc(number_of_order_times))
  ) %>% 
  filter(order_ranking < 4) %>% 
  select(-order_ranking)
  
most_popular_item

# Table showing mean hour of the day
mean_hour_of_the_day =
  instacart %>% 
  filter(
    product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  select(
    product_name,
    order_dow,
    order_hour_of_day) %>% 
  mutate(
    order_dow = wday(order_dow + 1, label = TRUE)) %>% 
  group_by(
    product_name,
    order_dow) %>% 
  summarize(
    mean_order_hour_of_day = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_order_hour_of_day
  )

mean_hour_of_the_day
```

Summary:

In the aisles_df, there are 134 rows and 3 variables which are aisle_id, aisle, and order_times. From this table, we know that there are 134 aisles and the aisle 83 which is corresponding to fresh vegetables is being ordered the most. From the plot, we notice that there are two aisle which are being ordered most. The data frame of most popular items have 9 rows and 4 variables which are aisle, product_name, number of order times, and order ranking. The most popular items in "baking ingredients" are 'Cane Sugar', 'Light Brown Sugar', and 'Pure Baking Soda'; in "dog food care" are 'Organix Chicken & Brown Rice Recipe', 'Small Dog Biscuits', and 'Snack Sticks Chicken & Rice Recipe Dog Treats'; in "packaged vegetables fruits" are 'Organic Baby Spinach', 'Organic Blueberries', and 'Organic Raspberries'. The table of mean hour of the day includes 2 rows which are 'Pink Lady Apples' and 'Coffee Ice Cream' and 8 variables which are corresponding to seven days in a week. The mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week is calculated.


## Problem 2

```{r, message=FALSE}
data("brfss_smart2010")

# Clean the data
brfss =
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health",
         response %in% c("Excellent","Poor", "Very good", "Good", "Fair")) %>% 
  mutate(
    response = forcats::fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))
  )
```

```{r}
# Find the states which were observed at 7 or more locations in 2002
locations_2002 =
  brfss %>% 
  filter(year == 2002) %>% 
  group_by(locationabbr) %>% 
  summarize(n_obs = n()) %>% 
  filter(n_obs >=7)

nrow(locations_2002)
pull(locations_2002,locationabbr)
```

```{r}
# Find the states which were observed at 7 or more locations in 2010
locations_2010 = 
  brfss %>% 
  filter(year == 2010) %>% 
  group_by(locationabbr) %>% 
  summarize(n_obs = n()) %>% 
  filter(n_obs >=7)

nrow(locations_2010)
pull(locations_2010,locationabbr)
```
* There are 36 states that were observed at 7 or more locations in 2002 and the names of locations are listed above.

* There are 45 states that were observed at 7 or more location in 2010 and the names of locations are listed above

```{r}
# Construct a data set and make a "spaghetti" plot
excellent_response = 
  brfss %>% 
  filter(response == "Excellent") %>% 
  select(year, locationabbr, data_value) %>% 
  group_by(year, locationabbr) %>% 
  summarize(average_data_value = mean(data_value, na.rm = T))

excellent_response %>% 
  ggplot(aes(x = year, y = average_data_value, color = locationabbr))+
  geom_line() +
  labs(
    title = "Figure 2. Average value over time within a state",
    x = "Year",
    y = "Average data value"
  ) 
```

```{r}
# Make two-panel plot
brfss %>%
  filter(locationabbr == "NY",
         year %in% c(2006,2010)) %>% 
  ggplot(aes(x = response, y = data_value)) +
  geom_point() + 
  geom_boxplot() +
  facet_grid(.~year)
```
In 2006, the mean value of data value is increasing from "Poor" to "Very good". The mean value of data value for "Excellent" is less than that for "Very good". The distribution of data value for "Good" is most widespread among all responses, In 2010, the mean value of data value is also increasing from "Poor" to "Very good". 

## Problem 3

```{r}
accel_df = 
  read_csv("accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    weekday_weekend = 
      ifelse(day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"), "weekday",
      ifelse(day %in% c("Saturday","Sunday"), "weekend", NA))) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "time",
    names_prefix = "activity_",
    values_to = "activity_count"
  )

```
The original data records the activity in 5 weeks which are 35 days. In each day, the activity data is recorded 1440 times. After tidying the data, we aggregate all variables starting with "activity_" into one column "time". Now, the data set includes 6 variable: week, day_id, day, weekday_weekend, time, and activity_count.

```{r}
#showing total activity for each day
total_activity =
  accel_df %>% 
  group_by(week, day_id) %>% 
  summarize(
    total_acti = sum(activity)
  )

ggplot(total_activity, aes(x = day_id, y = total_acti)) +
  geom_point() +
  geom_line()+
  labs(
    x = "Day",
    y = "Total Activity in a Day",
    title = "Figure3. Total activity in Each Day"
  ) +
  scale_y_continuous(
    breaks = c(0,1E05, 2E05, 3E05, 4E05, 5E05, 6E05, 7E05),
  )
```

```{r}
# showing the activity over the course of the day
accel_df %>% 
  group_by(day_id) %>% 
  ggplot(
    aes(x = activity_count,
    y = time, 
    color = week))+
  geom_point()


```

